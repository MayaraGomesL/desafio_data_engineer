# ğŸ“¦ Desafio Data Engineer â€” Pipeline (Bronze â†’ Silver â†’ Gold)

Pipeline de ingestÃ£o e transformaÃ§Ã£o dos Dados Abertos do CNPJ (Receita Federal) com PySpark + Delta Lake, orquestrado por Docker Compose e carga final no PostgreSQL.

---

## ğŸ§­ SumÃ¡rio

- [VisÃ£o Geral](#visÃ£o-geral)
- [Estrutura de Pastas](#estrutura-de-pastas)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [Como Rodar](#como-rodar)
- [Comandos Ãšteis](#comandos-Ãºteis)
- [ConfiguraÃ§Ãµes Importantes](#configuraÃ§Ãµes-importantes)
- [Limpeza / Reset](#limpeza--reset)
- [Troubleshooting](#troubleshooting)
- [LicenÃ§a & Fontes](#licenÃ§a--fontes)

---

## âœ¨ VisÃ£o Geral

- **Fonte:** Ãndice pÃºblico da Receita Federal (dados abertos do CNPJ), via HTTP usando `requests` + `BeautifulSoup`.
- **Raw:** Zips baixados e extraÃ­dos localmente (arquivos `...EMPRECSV`, `...SOCIOCSV`).
- **Bronze (Delta):** Dados brutos com schema aplicado e partiÃ§Ã£o por `ano_mes`.
- **Silver (Delta):** NormalizaÃ§Ã£o (tipos, limpeza, padronizaÃ§Ãµes) e deduplicaÃ§Ã£o antes do MERGE (upsert).
- **Gold:** AgregaÃ§Ã£o final (`gold_flat_emp_socios`) e escrita direta no PostgreSQL.

---

## ğŸ“ Estrutura de Pastas


```
.
â”œâ”€ config/
â”‚  â”œâ”€ variables.py          # caminhos, JDBC, nomes de tabelas
â”‚  â””â”€ schemas.py            # schemas das tabelas Bronze e Silver
â”œâ”€ src/
â”‚  â”œâ”€ pipeline.py           # orquestra o fluxo end-to-end
â”‚  â”œâ”€ utils/
â”‚  â”‚  â”œâ”€ spark_session.py   # get_spark() com Delta + driver JDBC
â”‚  â”‚  â”œâ”€ utils.py           # helpers: http_session, get_html_links, unzip, metadados, read_delta
â”‚  â”‚  â””â”€ download_html.py   # listar meses/zips, validar, baixar e extrair
â”‚  â”œâ”€ bronze/
â”‚  â”‚  â””â”€ bronze_ingestion.py   # write_bronze_append (CSV â†’ Delta Bronze)
â”‚  â”œâ”€ silver/
â”‚  â”‚  â””â”€ silver_ingestion.py   # normalizaÃ§Ãµes + write_silver_merge (dropDuplicates + merge)
â”‚  â””â”€ gold/
â”‚     â”œâ”€ transform_gold.py     # criar_gold_flat_emp_socios
â”‚     â””â”€ load_gold.py          # write_gold_to_postgres
â”œâ”€ data/                    # Armazenamento local (nÃ£o versionado)
â”‚  â”œâ”€ bronze/
â”‚  â”œâ”€ silver/
â”‚  â”œâ”€ gold/
â”‚  â””â”€ work/
â”‚     â””â”€ zips/              # zips baixados
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## âœ… PrÃ©-requisitos

- Docker + Docker Compose
- ConexÃ£o de rede (para baixar os arquivos da RFB)

---

## â–¶ï¸ Como Rodar

### 1) Build (opcional) e execuÃ§Ã£o do pipeline

**Build da imagem:**
```sh
docker compose build
```

**Rodar pipeline (one-shot):**
```sh
# Sintaxe:
docker compose run --rm app python -m src.pipeline <YYYY-MM> <EMP_ID> <SOC_ID>

# Exemplo (baixa Empresas1.zip e Socios1.zip do mÃªs 2025-09):
docker compose run --rm app python -m src.pipeline 2025-09 1 1
```
> `EMP_ID` / `SOC_ID` correspondem aos sufixos dos zips listados no Ã­ndice (ex.: Empresas1.zip / Socios1.zip). Caso o ano-mes solicitado ou Empresas/Socios nÃ£o seja localizado lista pastas disponÃ­veis para download.

---

## ğŸ” Comandos Ãšteis

### Ver Bronze (exemplo empresas do mÃªs)
```sh
docker compose run --rm app python - <<'PY'
from pyspark.sql import SparkSession as S
s = S.builder.getOrCreate()
df = s.read.format("delta").load("/app/data/bronze/empresas")
df.where("ano_mes='2025-09'").show(20, False)
PY
```

### Exportar amostra da Silver (500 linhas) para CSV
```sh
docker compose run --rm app python - <<'PY'
import os, glob, shutil
from pyspark.sql import SparkSession as S
s = S.builder.getOrCreate()
df = s.read.format("delta").load("/app/data/silver/socios").limit(500)
tmp = "/app/data/samples/_silver_socios_head500"
out = "/app/data/samples/silver_socios_head500.csv"
(df.coalesce(1).write.mode("overwrite").option("header","true").csv(tmp))
os.makedirs("/app/data/samples", exist_ok=True)
part = glob.glob(os.path.join(tmp,"part-*.csv"))[0]
shutil.move(part, out)
shutil.rmtree(tmp)
print("Arquivo gerado:", out)
PY
```

### Consultar GOLD no Postgres
```sh
docker compose exec -it db psql -U postgres -d ml_data_engineer_sql -c "SELECT * FROM gold_flat_emp_socios LIMIT 10;"
```

---

## ğŸ§¹ Limpeza / Reset

### Limpar dados do data lake (ATENÃ‡ÃƒO: remove bronze/silver/gold e temporÃ¡rios)
```sh
docker compose run --rm app bash -lc "rm -rf /app/data/bronze /app/data/silver /app/data/gold /app/data/work/* && mkdir -p /app/data/work/zips"
```

### Resetar tabela GOLD no Postgres
```sh
docker compose exec -it db psql -U postgres -d ml_data_engineer_sql -c "DROP TABLE IF EXISTS gold_flat_emp_socios;"
```

---

## ğŸ› ï¸ Troubleshooting

- **Failed to find the data source: delta**  
  Falta o pacote do Delta no Spark. Garanta que o `spark.jars.packages` inclui `io.delta:delta-spark_2.13:4.0.0` e que a `SparkSession` habilita a extensÃ£o `DeltaSparkSessionExtension`.

- **java.lang.ClassNotFoundException: org.postgresql.Driver**  
  Inclua `org.postgresql:postgresql:42.7.3` em `spark.jars.packages` ou adicione o JAR ao classpath.

---

## ğŸ“ LicenÃ§a & Fontes

**Dados:** Receita Federal do Brasil â€” Dados Abertos do CNPJ.
Este repositÃ³rio tem carÃ¡ter nÃ£o oficial.
